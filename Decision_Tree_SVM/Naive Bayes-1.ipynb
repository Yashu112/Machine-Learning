{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d33c498-20b7-42a0-8eba-618364d27557",
   "metadata": {},
   "source": [
    "# Naive Baiyes-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dee1b7-3313-4ee1-8e42-db28cb48bc9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c80841a-2eb6-422d-8afa-7a20217da7f5",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Ans. Bayes' theorem, is a fundamental theorem in probability theory and statistics. It describes how to update the probability for a hypothesis based on new evidence. Bayes' theorem is widely used in various fields, including statistics, machine learning, and Bayesian inference. The theorem is expressed as follows:\n",
    "\n",
    "$$ P\\left(A|B\\right) = \\frac{P\\left(A\\right).P\\left(B|A\\right)}{P\\left(B\\right)}$$\n",
    "\n",
    "where:\n",
    "- $ P\\left(A|B\\right)$: Probability of occurenc of A given B is true\n",
    "- $ P\\left(B|A\\right)$: Probability of occurenc of B given A is true\n",
    "- $ P(A) $: Probability of occurenc of A \n",
    "- $ P(B) $: Probability of occurenc of B\n",
    "\n",
    "Bayes' theorem is foundational in Bayesian statistics and Bayesian inference, where it is used for various purposes, including parameter estimation, classification, and hypothesis testing. It provides a principled framework for incorporating new information into your understanding of a problem and making informed decisions based on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631726d-703c-42d9-945a-ef0dfa7f3b70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ceb1a9-9654-4fc4-90a5-e3f33f1177af",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Ans. Formula for Bayes' Theorem for 2 events:\n",
    "\n",
    "$$ P\\left(A|B\\right) = \\frac{P\\left(A\\right).P\\left(B|A\\right)}{P\\left(B\\right)}$$\n",
    "\n",
    "where:\n",
    "- $ P\\left(A|B\\right)$: Probability of occurenc of A given B is true\n",
    "- $ P\\left(B|A\\right)$: Probability of occurenc of B given A is true\n",
    "- $ P(A) $: Probability of occurenc of A \n",
    "- $ P(B) $: Probability of occurenc of B\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe55bfa-f0ca-4b08-b2e1-889c146128d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31730449-b1b7-4699-a89a-8d388c46bf77",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Ans. Bayes' theorem is used in practice in various fields and applications where probabilistic reasoning and updating beliefs based on evidence are essential. Here are some common ways Bayes' theorem is used in practice:\n",
    "\n",
    "1. **Bayesian Inference**: Bayes' theorem forms the foundation of Bayesian inference, a powerful statistical framework. It is used to update prior beliefs about model parameters or hypotheses based on observed data. Bayesian inference is prevalent in fields such as machine learning, statistics, and data science for tasks like parameter estimation, model selection, and uncertainty quantification.\n",
    "\n",
    "2. **Medical Diagnosis**: In medicine, Bayes' theorem is used for diagnostic purposes. It helps calculate the probability of a disease given certain symptoms or test results. For example, it's used in medical tests like mammograms, where the probability of breast cancer is estimated based on test results and prior probabilities.\n",
    "\n",
    "3. **Spam Filtering**: Bayes' theorem is used in spam email filters. It calculates the probability that an incoming email is spam or not spam based on the presence of specific words or patterns in the email content. The model continually updates its probabilities as it encounters new emails.\n",
    "\n",
    "4. **Natural Language Processing (NLP)**: In NLP, Bayes' theorem is used in tasks like text classification, sentiment analysis, and spam detection. It helps calculate the probability of a document belonging to a particular category or having a specific sentiment based on the words or features present in the text.\n",
    "\n",
    "5. **Machine Learning**: Bayesian methods are used in machine learning, particularly in probabilistic graphical models like Bayesian networks and Markov Chain Monte Carlo (MCMC) algorithms. These methods are used for tasks like probabilistic modeling, Bayesian regression, and probabilistic classification.\n",
    "\n",
    "6. **Finance and Risk Assessment**: Bayes' theorem is applied in finance for portfolio optimization, risk assessment, and fraud detection. It helps estimate the likelihood of financial events or market movements based on historical data and other factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25adb39-0699-4630-a2a0-f8ad7be8a3af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc2c88d-8c6c-4362-85bb-42c450417529",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Ans. Bayes' theorem and conditional probability are closely related concepts in probability theory. Bayes' theorem is a mathematical formula that provides a way to update conditional probabilities based on new evidence or information. In fact, Bayes' theorem can be seen as a direct application of conditional probability.\n",
    "\n",
    "Here is the relationship between Bayes' theorem and conditional probability:\n",
    "\n",
    "1. **Bayes' Theorem as an Extension of Conditional Probability**:\n",
    "\n",
    "   Bayes' theorem extends the concept of conditional probability. Conditional probability is the probability of an event occurring given that another event has already occurred. It is denoted as \\(P(A|B)\\), which represents the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "   Bayes' theorem takes this further by allowing you to update your belief in the probability of one event (A) based on the occurrence of another event (B) and their prior probabilities:\n",
    "\n",
    " $$ P\\left(A|B\\right) = \\frac{P\\left(A\\right) \\cdot P\\left(B|A\\right)}{P\\left(B\\right)}$$\n",
    "\n",
    "2. **Using Bayes' Theorem for Conditional Probability**:\n",
    "\n",
    "   Bayes' theorem is a tool for updating conditional probabilities in situations where you have prior beliefs (prior probabilities) and new evidence (likelihoods) that affect your assessment of conditional probabilities. It allows you to revise your estimates based on the interplay between prior knowledge and new observations.\n",
    "\n",
    "3. **Applications**:\n",
    "\n",
    "   - Conditional probability is used to find the likelihood of an event given certain conditions, and it is foundational in probability theory.\n",
    "   - Bayes' theorem is widely applied in Bayesian inference, machine learning, statistics, and various real-world scenarios to update and revise probabilities based on evidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b79246-273c-4a94-bcaf-68a03ee344c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "626b5a99-2c94-43f8-936a-3742adef0b53",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Ans. Choosing the appropriate type of Naive Bayes classifier for a given problem depends on the nature of the data and the assumptions that best fit the problem's characteristics. There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's how to make a choice:\n",
    "\n",
    "1. **Gaussian Naive Bayes**: Gaussian Naive Bayes is suitable for continuous numerical data that follows a Gaussian (normal) distribution. It assumes that features are normally distributed within each class.It is commonly used in problems involving real-valued features such as measurements, sensor data, or any data that can be modeled as continuous variables.\n",
    "\n",
    "2. **Multinomial Naive Bayes**: Multinomial Naive Bayes is appropriate for discrete data, particularly when dealing with count-based or frequency-based data. It is often used with text data where features represent word frequencies or document-term frequencies. Text classification tasks, spam detection, sentiment analysis, and document categorization are typical applications where Multinomial Naive Bayes is effective.\n",
    "\n",
    "3. **Bernoulli Naive Bayes**: Bernoulli Naive Bayes is suitable for binary data, where features are either present (1) or absent (0). It is often used in text classification problems where the presence or absence of words in a document is important. Text classification, sentiment analysis, and document categorization involving binary feature representations (e.g., bag-of-words with binary values).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562de32b-234e-4b14-aca1-ec35a31745ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126a15c7-0f76-4c25-92c5-1b603caa2041",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "|Class| X1=1| X1=2| X1=3 |X2=1 |X2=2 |X2=3| X2=4|\n",
    "|---| ---| ---| --- |---|--- |---| ----|\n",
    "|A| 3| 3| 4| 4| 3| 3| 3|\n",
    "|B| 2| 2| 1| 2| 2| 2| 3|\n",
    "\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\n",
    "\n",
    "Ans. To classify a new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we can calculate the posterior probabilities for each class (A and B) and then choose the class with the higher posterior probability. We'll assume equal prior probabilities for each class, so we don't need to consider them in the calculation. \n",
    "\n",
    "Let's calculate the posterior probabilities for both classes:\n",
    "\n",
    "**For Class A:**\n",
    "- $P(X_1 = 3 | A)$ = 4/23 (based on the table)\n",
    "- $P(X_2 = 4 | A)$ = 3/23 (based on the table)\n",
    "- $P(X_1 = 3, X_2 = 4 | A)$ = (4/23) * (3/23) = 0.0227\n",
    "- $P(A) = 23/37 = 0.62$\n",
    "\n",
    "**For Class B:**\n",
    "- $P(X_1 = 3 | B)$ = 1/14 (based on the table)\n",
    "- $P(X_2 = 4 | B)$ = 3/14 (based on the table)\n",
    "- $P(X_1 = 3, X_2 = 4 | B)$ = (1/14) * (3/14) = 0.015\n",
    "- $P(B) = 14/37 = 0.38$\n",
    "Now, we can calculate the posterior probabilities using Bayes' theorem:\n",
    "\n",
    " $$ P\\left(Y|(X_1,X_2)\\right) = \\frac{P\\left(Y\\right) \\cdot P\\left((X_1,X_2)|Y\\right)}{P\\left((X_1,X_2)\\right)}$$\n",
    "\n",
    "We can see that we only need to compare the numerators of the two proportions since the denominators (the marginal likelihoods P(X1 = 3, X2 = 4)) are the same for both classes. Therefore, we choose the class with the higher numerator.\n",
    "\n",
    "$$ P\\left(Y|(X_1,X_2)\\right) \\propto \\left(Y\\right) \\cdot P\\left((X_1,X_2)|Y\\right)$$\n",
    "\n",
    "**For Class A:**\n",
    "- $P(A | X1 = 3, X2 = 4) \\propto P(A) \\cdot P(X1 = 3 and X2 = 4 | A) $\n",
    "- $P(A | X1 = 3, X2 = 4) \\propto 0.62 *0.0227 $\n",
    "- $P(A | X1 = 3, X2 = 4) \\propto 0.014 $\n",
    "\n",
    "**For Class B:**\n",
    "- $P(B | X1 = 3, X2 = 4) \\propto P(B) \\cdot P(X1 = 3 and X2 = 4 | B) $\n",
    "- $P(B | X1 = 3, X2 = 4) \\propto 0.38 * 0.015 $\n",
    "- $P(B | X1 = 3, X2 = 4) \\propto 0.0057 $\n",
    "\n",
    "We can see that we only need to compare the numerators of the two proportions since the denominators (the marginal likelihoods P(X1 = 3, X2 = 4)) are the same for both classes. Therefore, we choose the class with the higher numerator.\n",
    "\n",
    " $$0.014 \\gt 0.0057$$\n",
    " \n",
    " $$\\implies P(A | X1 = 3, X2 = 4) \\gt P(B | X1 = 3, X2 = 4)$$\n",
    "\n",
    "Since $P(A | X1 = 3, X2 = 4)$ is greater than $P(A | X1 = 3, X2 = 4)$, the Naive Bayes classifier would predict that the new instance with features X1 = 3 and X2 = 4 belongs to **Class A**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca56b14-17c1-4c9b-8c7c-d5b19f7deeb4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
